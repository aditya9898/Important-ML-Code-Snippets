{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport tensorflow as tf\nimport os\nimport scipy.io",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "collapsed": true,
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": false
      },
      "cell_type": "markdown",
      "source": "**Download the pretrained VGG-19 weights trained on the imagenet dataset from the link below.**\nhttp://www.vlfeat.org/matconvnet/models/imagenet-vgg-verydeep-19.mat"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "39e324c474a834d2ee1d97a89fcbd9f33e06e169"
      },
      "cell_type": "code",
      "source": "!wget http://www.vlfeat.org/matconvnet/models/imagenet-vgg-verydeep-19.mat -O vgg19.mat",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "--2018-08-30 18:34:10--  http://www.vlfeat.org/matconvnet/models/imagenet-vgg-verydeep-19.mat\nResolving www.vlfeat.org (www.vlfeat.org)... 64.90.48.57\nConnecting to www.vlfeat.org (www.vlfeat.org)|64.90.48.57|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 534904783 (510M) [text/plain]\nSaving to: ‘vgg19.mat’\n\nvgg19.mat           100%[=====================>] 510.12M  41.6MB/s   in 14s    \n\n2018-08-30 18:34:24 (36.6 MB/s) - ‘vgg19.mat’ saved [534904783/534904783]\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "91cb8e8524c7e6c1ce3ddc508708d26d818188c7"
      },
      "cell_type": "markdown",
      "source": "**Given below is the function to create the VGG-19 model using the path to the pretrained-weights.mat .**"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "ba26639b8e4a449e83aa03efe790c883bdd894cc"
      },
      "cell_type": "code",
      "source": "def load_vgg_model(path):\n    \"\"\"\n    Returns a model for the purpose of 'painting' the picture.\n    Takes only the convolution layer weights and wrap using the TensorFlow\n    Conv2d, Relu and AveragePooling layer. VGG actually uses maxpool but\n    the paper indicates that using AveragePooling yields better results.\n    The last few fully connected layers are not used.\n    Here is the detailed configuration of the VGG model:\n        0 is conv1_1 (3, 3, 3, 64)\n        1 is relu\n        2 is conv1_2 (3, 3, 64, 64)\n        3 is relu    \n        4 is maxpool\n        5 is conv2_1 (3, 3, 64, 128)\n        6 is relu\n        7 is conv2_2 (3, 3, 128, 128)\n        8 is relu\n        9 is maxpool\n        10 is conv3_1 (3, 3, 128, 256)\n        11 is relu\n        12 is conv3_2 (3, 3, 256, 256)\n        13 is relu\n        14 is conv3_3 (3, 3, 256, 256)\n        15 is relu\n        16 is conv3_4 (3, 3, 256, 256)\n        17 is relu\n        18 is maxpool\n        19 is conv4_1 (3, 3, 256, 512)\n        20 is relu\n        21 is conv4_2 (3, 3, 512, 512)\n        22 is relu\n        23 is conv4_3 (3, 3, 512, 512)\n        24 is relu\n        25 is conv4_4 (3, 3, 512, 512)\n        26 is relu\n        27 is maxpool\n        28 is conv5_1 (3, 3, 512, 512)\n        29 is relu\n        30 is conv5_2 (3, 3, 512, 512)\n        31 is relu\n        32 is conv5_3 (3, 3, 512, 512)\n        33 is relu\n        34 is conv5_4 (3, 3, 512, 512)\n        35 is relu\n        36 is maxpool\n        37 is fullyconnected (7, 7, 512, 4096)\n        38 is relu\n        39 is fullyconnected (1, 1, 4096, 4096)\n        40 is relu\n        41 is fullyconnected (1, 1, 4096, 1000)\n        42 is softmax\n    \"\"\"\n    \n    vgg = scipy.io.loadmat(path)\n\n    vgg_layers = vgg['layers']\n    \n    def _weights(layer, expected_layer_name):\n        \"\"\"\n        Return the weights and bias from the VGG model for a given layer.\n        \"\"\"\n        wb = vgg_layers[0][layer][0][0][2]\n        W = wb[0][0]\n        b = wb[0][1]\n        layer_name = vgg_layers[0][layer][0][0][0][0]\n        assert layer_name == expected_layer_name\n        return W, b\n\n        return W, b\n\n    def _relu(conv2d_layer):\n        \"\"\"\n        Return the RELU function wrapped over a TensorFlow layer. Expects a\n        Conv2d layer input.\n        \"\"\"\n        return tf.nn.relu(conv2d_layer)\n\n    def _conv2d(prev_layer, layer, layer_name):\n        \"\"\"\n        Return the Conv2D layer using the weights, biases from the VGG\n        model at 'layer'.\n        \"\"\"\n        W, b = _weights(layer, layer_name)\n        W = tf.constant(W)\n        b = tf.constant(np.reshape(b, (b.size)))\n        return tf.nn.conv2d(prev_layer, filter=W, strides=[1, 1, 1, 1], padding='SAME') + b\n\n    def _conv2d_relu(prev_layer, layer, layer_name):\n        \"\"\"\n        Return the Conv2D + RELU layer using the weights, biases from the VGG\n        model at 'layer'.\n        \"\"\"\n        return _relu(_conv2d(prev_layer, layer, layer_name))\n\n    def _avgpool(prev_layer):\n        \"\"\"\n        Return the AveragePooling layer.\n        \"\"\"\n        return tf.nn.avg_pool(prev_layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n\n    # Constructs the graph model.\n    graph = {}\n    graph['input']   = tf.Variable(np.zeros((1, CONFIG.IMAGE_HEIGHT, CONFIG.IMAGE_WIDTH, CONFIG.COLOR_CHANNELS)), dtype = 'float32')\n    graph['conv1_1']  = _conv2d_relu(graph['input'], 0, 'conv1_1')\n    graph['conv1_2']  = _conv2d_relu(graph['conv1_1'], 2, 'conv1_2')\n    graph['avgpool1'] = _avgpool(graph['conv1_2'])\n    graph['conv2_1']  = _conv2d_relu(graph['avgpool1'], 5, 'conv2_1')\n    graph['conv2_2']  = _conv2d_relu(graph['conv2_1'], 7, 'conv2_2')\n    graph['avgpool2'] = _avgpool(graph['conv2_2'])\n    graph['conv3_1']  = _conv2d_relu(graph['avgpool2'], 10, 'conv3_1')\n    graph['conv3_2']  = _conv2d_relu(graph['conv3_1'], 12, 'conv3_2')\n    graph['conv3_3']  = _conv2d_relu(graph['conv3_2'], 14, 'conv3_3')\n    graph['conv3_4']  = _conv2d_relu(graph['conv3_3'], 16, 'conv3_4')\n    graph['avgpool3'] = _avgpool(graph['conv3_4'])\n    graph['conv4_1']  = _conv2d_relu(graph['avgpool3'], 19, 'conv4_1')\n    graph['conv4_2']  = _conv2d_relu(graph['conv4_1'], 21, 'conv4_2')\n    graph['conv4_3']  = _conv2d_relu(graph['conv4_2'], 23, 'conv4_3')\n    graph['conv4_4']  = _conv2d_relu(graph['conv4_3'], 25, 'conv4_4')\n    graph['avgpool4'] = _avgpool(graph['conv4_4'])\n    graph['conv5_1']  = _conv2d_relu(graph['avgpool4'], 28, 'conv5_1')\n    graph['conv5_2']  = _conv2d_relu(graph['conv5_1'], 30, 'conv5_2')\n    graph['conv5_3']  = _conv2d_relu(graph['conv5_2'], 32, 'conv5_3')\n    graph['conv5_4']  = _conv2d_relu(graph['conv5_3'], 34, 'conv5_4')\n    graph['avgpool5'] = _avgpool(graph['conv5_4'])\n    \n    return graph\n",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e1e4d51d404eb37cd546292313c65a5a65bf1506"
      },
      "cell_type": "markdown",
      "source": "**This class [CONFIG] is required to form the input base of the model. You can find other means to do the same.**"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "8ce3b328c1714213ec651ce97b9f7a6af5ada523"
      },
      "cell_type": "code",
      "source": "class CONFIG:\n    IMAGE_WIDTH = 512\n    IMAGE_HEIGHT = 512\n    COLOR_CHANNELS = 3",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f56ff5ce9a80bcac7934f5ddadc180352f779fc2"
      },
      "cell_type": "markdown",
      "source": "**Here's how to create the model with a function call to the load_vgg_model() function.**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5da818f7cf29c0eeb3f501d735d656425129b97c"
      },
      "cell_type": "code",
      "source": "path='vgg19.mat'\nmodel=load_vgg_model(path)\nprint(model)",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "{'input': <tf.Variable 'Variable:0' shape=(1, 512, 512, 3) dtype=float32_ref>, 'conv1_1': <tf.Tensor 'Relu:0' shape=(1, 512, 512, 64) dtype=float32>, 'conv1_2': <tf.Tensor 'Relu_1:0' shape=(1, 512, 512, 64) dtype=float32>, 'avgpool1': <tf.Tensor 'AvgPool:0' shape=(1, 256, 256, 64) dtype=float32>, 'conv2_1': <tf.Tensor 'Relu_2:0' shape=(1, 256, 256, 128) dtype=float32>, 'conv2_2': <tf.Tensor 'Relu_3:0' shape=(1, 256, 256, 128) dtype=float32>, 'avgpool2': <tf.Tensor 'AvgPool_1:0' shape=(1, 128, 128, 128) dtype=float32>, 'conv3_1': <tf.Tensor 'Relu_4:0' shape=(1, 128, 128, 256) dtype=float32>, 'conv3_2': <tf.Tensor 'Relu_5:0' shape=(1, 128, 128, 256) dtype=float32>, 'conv3_3': <tf.Tensor 'Relu_6:0' shape=(1, 128, 128, 256) dtype=float32>, 'conv3_4': <tf.Tensor 'Relu_7:0' shape=(1, 128, 128, 256) dtype=float32>, 'avgpool3': <tf.Tensor 'AvgPool_2:0' shape=(1, 64, 64, 256) dtype=float32>, 'conv4_1': <tf.Tensor 'Relu_8:0' shape=(1, 64, 64, 512) dtype=float32>, 'conv4_2': <tf.Tensor 'Relu_9:0' shape=(1, 64, 64, 512) dtype=float32>, 'conv4_3': <tf.Tensor 'Relu_10:0' shape=(1, 64, 64, 512) dtype=float32>, 'conv4_4': <tf.Tensor 'Relu_11:0' shape=(1, 64, 64, 512) dtype=float32>, 'avgpool4': <tf.Tensor 'AvgPool_3:0' shape=(1, 32, 32, 512) dtype=float32>, 'conv5_1': <tf.Tensor 'Relu_12:0' shape=(1, 32, 32, 512) dtype=float32>, 'conv5_2': <tf.Tensor 'Relu_13:0' shape=(1, 32, 32, 512) dtype=float32>, 'conv5_3': <tf.Tensor 'Relu_14:0' shape=(1, 32, 32, 512) dtype=float32>, 'conv5_4': <tf.Tensor 'Relu_15:0' shape=(1, 32, 32, 512) dtype=float32>, 'avgpool5': <tf.Tensor 'AvgPool_4:0' shape=(1, 16, 16, 512) dtype=float32>}\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "24ebdd19db4cc48034242c8a260bbd27983b61f6"
      },
      "cell_type": "markdown",
      "source": "**Here's how to use the model**\n1. assign the input of the model with the image that we wish to pass through the model.\n2. get the output tensor of a particular layer using output=model['layer_name'].\n3. get the values of that output tensor by running  with a session."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "44e63cd1db394a89d5945ea987e6403bc06c094c"
      },
      "cell_type": "code",
      "source": "# making a random image to pass through the model\nrand=np.random.uniform(0,255,(1,512,512,3))\n# notice the input that we feed to the model is four-dimentional\n# now assigning the models input as the image that we feed in.\n#create a session for this\ninit=tf.global_variables_initializer()\nsess=tf.Session()\nsess.run(init)\nmodel['input'].assign(rand)\n# now supose we want the output of layer 'conv1_1'\nout=model['conv1_1']\noutput_vals=sess.run(out)",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0e60fbfd5a9eefbb3662e675418f06c3e19bf702"
      },
      "cell_type": "code",
      "source": "output_vals.shape",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "(1, 512, 512, 64)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "f66997ea5e27e5217d35c0c0e385df433ac8d6e2"
      },
      "cell_type": "markdown",
      "source": "**Here we have got th eoutput values of that particular layer.**"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "19056eee91a159ca1836936706ecafe97c2299a3"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}